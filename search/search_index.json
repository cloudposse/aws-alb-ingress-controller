{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AWS ALB Ingress Controller \u00b6 NOTE: This controller is in beta state as we attempt to move to our first 1.0 release. The current image version is 1.0-beta.7 . Please file any issues you find and note the version used. The AWS ALB Ingress Controller satisfies Kubernetes ingress resources by provisioning Application Load Balancers . This project was originated by Ticketmaster and CoreOS as part of Ticketmaster's move to AWS and CoreOS Tectonic. Learn more about Ticketmaster's Kubernetes initiative from Justin Dean's video at Tectonic Summit . This project was donated to Kubernetes SIG-AWS to allow AWS, CoreOS, Ticketmaster and other SIG-AWS contributors to officially maintain the project. SIG-AWS reached this consensus on June 1, 2018. Documentation \u00b6 Checkout our Live Docs ! Getting started \u00b6 To get started with the controller, see our walkthrough . Setup \u00b6 See controller setup on how to install ALB ingress controller See external-dns setup for how to setup the external-dns to manage route 53 records. Building \u00b6 For details on building this project, see BUILDING.md . License \u00b6","title":"Welcome"},{"location":"#aws-alb-ingress-controller","text":"NOTE: This controller is in beta state as we attempt to move to our first 1.0 release. The current image version is 1.0-beta.7 . Please file any issues you find and note the version used. The AWS ALB Ingress Controller satisfies Kubernetes ingress resources by provisioning Application Load Balancers . This project was originated by Ticketmaster and CoreOS as part of Ticketmaster's move to AWS and CoreOS Tectonic. Learn more about Ticketmaster's Kubernetes initiative from Justin Dean's video at Tectonic Summit . This project was donated to Kubernetes SIG-AWS to allow AWS, CoreOS, Ticketmaster and other SIG-AWS contributors to officially maintain the project. SIG-AWS reached this consensus on June 1, 2018.","title":"AWS ALB Ingress Controller"},{"location":"#documentation","text":"Checkout our Live Docs !","title":"Documentation"},{"location":"#getting-started","text":"To get started with the controller, see our walkthrough .","title":"Getting started"},{"location":"#setup","text":"See controller setup on how to install ALB ingress controller See external-dns setup for how to setup the external-dns to manage route 53 records.","title":"Setup"},{"location":"#building","text":"For details on building this project, see BUILDING.md .","title":"Building"},{"location":"#license","text":"","title":"License"},{"location":"BUILDING/","text":"Building \u00b6 Download this repo locally \u00b6 $ go get -d github.com/kubernetes-sigs/aws-alb-ingress-controller $ cd $GOPATH /src/github.com/kubernetes-sigs/aws-alb-ingress-controller Build the binary and container with the Makefile \u00b6 $ make clean ; make Verify the local container is known to your Docker daemon \u00b6 $ docker images | grep -i alb-ingress-controller quay.io/coreos/alb-ingress-controller 1 .0-beta.4 78f356144e33 20 minutes ago 47 .4MB Version can vary based on what's in the Makefile. If you wish to push to your own repo for testing, you can change the version and repo details in the Makefile then do a docker push . Running locally \u00b6 If you'd like to make modifications and run this controller locally for the purpose of debugging, the following script can be used a basis for how to bootstrap the controller. It assumes you have a default kubeconfig for your cluster at ~/.kube/config . #!/bin/bash KUBECTL_PROXY_PID = $( pgrep -fx \"kubectl proxy\" ) echo $KUBECTL_PROXY_PID if [[ -z $KUBECTL_PROXY_PID ]] then echo \"kubectl proxy was not running. Starting it.\" else echo \"Found kubectl proxy is running. Killing it. Starting it.\" kill $KUBECTL_PROXY_PID fi kubectl proxy & >/dev/null & kubectl apply -f ./examples/echoservice/echoserver-namespace.yaml kubectl apply -f ./examples/echoservice/echoserver-deployment.yaml kubectl apply -f ./examples/echoservice/echoserver-service.yaml kubectl apply -f ./examples/echoservice/echoserver-ingress2.yaml $ make server Or on MacOS $ OS = darwin make server $ AWS_REGION = us-west-2 POD_NAME = alb-ingress-controller POD_NAMESPACE = kube-system go run cmd/main.go --apiserver-host = http://localhost:8001 --cluster-name = devcluster","title":"Building"},{"location":"BUILDING/#building","text":"","title":"Building"},{"location":"BUILDING/#download-this-repo-locally","text":"$ go get -d github.com/kubernetes-sigs/aws-alb-ingress-controller $ cd $GOPATH /src/github.com/kubernetes-sigs/aws-alb-ingress-controller","title":"Download this repo locally"},{"location":"BUILDING/#build-the-binary-and-container-with-the-makefile","text":"$ make clean ; make","title":"Build the binary and container with the Makefile"},{"location":"BUILDING/#verify-the-local-container-is-known-to-your-docker-daemon","text":"$ docker images | grep -i alb-ingress-controller quay.io/coreos/alb-ingress-controller 1 .0-beta.4 78f356144e33 20 minutes ago 47 .4MB Version can vary based on what's in the Makefile. If you wish to push to your own repo for testing, you can change the version and repo details in the Makefile then do a docker push .","title":"Verify the local container is known to your Docker daemon"},{"location":"BUILDING/#running-locally","text":"If you'd like to make modifications and run this controller locally for the purpose of debugging, the following script can be used a basis for how to bootstrap the controller. It assumes you have a default kubeconfig for your cluster at ~/.kube/config . #!/bin/bash KUBECTL_PROXY_PID = $( pgrep -fx \"kubectl proxy\" ) echo $KUBECTL_PROXY_PID if [[ -z $KUBECTL_PROXY_PID ]] then echo \"kubectl proxy was not running. Starting it.\" else echo \"Found kubectl proxy is running. Killing it. Starting it.\" kill $KUBECTL_PROXY_PID fi kubectl proxy & >/dev/null & kubectl apply -f ./examples/echoservice/echoserver-namespace.yaml kubectl apply -f ./examples/echoservice/echoserver-deployment.yaml kubectl apply -f ./examples/echoservice/echoserver-service.yaml kubectl apply -f ./examples/echoservice/echoserver-ingress2.yaml $ make server Or on MacOS $ OS = darwin make server $ AWS_REGION = us-west-2 POD_NAME = alb-ingress-controller POD_NAMESPACE = kube-system go run cmd/main.go --apiserver-host = http://localhost:8001 --cluster-name = devcluster","title":"Running locally"},{"location":"CODE_OF_CONDUCT/","text":"Kubernetes Community Code of Conduct Kubernetes follows the CNCF Code of Conduct","title":"CODE OF CONDUCT"},{"location":"CONTRIBUTING/","text":"Contributing \u00b6 Thanks for taking the time to join our community and start contributing! The Contributor Guide provides detailed instructions on how to get your ideas and bug fixes seen and accepted. Please remember to sign the CNCF CLA and read and observe the Code of Conduct .","title":"Contributing"},{"location":"CONTRIBUTING/#contributing","text":"Thanks for taking the time to join our community and start contributing! The Contributor Guide provides detailed instructions on how to get your ideas and bug fixes seen and accepted. Please remember to sign the CNCF CLA and read and observe the Code of Conduct .","title":"Contributing"},{"location":"ROADMAP/","text":"v1.1.0 \u00b6 support sharing ALB between ingresses across namespace support AWS Cognito","title":"Roadmap"},{"location":"ROADMAP/#v110","text":"support sharing ALB between ingresses across namespace support AWS Cognito","title":"v1.1.0"},{"location":"guide/controller/config/","text":"ALB Ingress Controller Configuration \u00b6 This document covers configuration of the ALB ingress controller AWS API Access \u00b6 To perform operations, the controller must have required IAM role capabilities for accessing and provisioning ALB resources. There are many ways to achieve this, such as loading AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY as environment variables or using kube2iam . A sample IAM policy, with the minimum permissions to run the controller, can be found in alb-iam-policy.json . Setting Ingress Resource Scope \u00b6 You can limit the ingresses ALB ingress controller controls by combining following two approaches: Limiting ingress class \u00b6 Setting the --ingress-class argument constrains the controller's scope to ingresses with matching kubernetes.io/ingress.class annotation. This is especially helpful when running multiple ingress controllers in the same cluster. See Using Multiple Ingress Controllers for more details. An example of the container spec portion of the controller, only listening for resources with the class \"alb\", would be as follows. spec : containers : - args : - --ingress-class=alb Now, only ingress resources with the appropriate annotation are picked up, as seen below. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : echoserver namespace : echoserver annotations : kubernetes.io/ingress.class : \"alb\" spec : ... Limiting Namespaces \u00b6 Setting the --watch-namespace argument constrains the controller's scope to a single namespace. Ingress events outside of the namespace specified are not be seen by the controller. An example of the container spec, for a controller watching only the default namespace, is as follows. spec : containers : - args : - --watch-namespace=default Currently, you can set only 1 namespace to watch in this flag. See this Kubernetes issue for more details. Limiting External Namespaces \u00b6 Setting the --restrict-scheme boolean flag to true will enable the ALB controller to check the configmap named alb-ingress-controller-internet-facing-ingresses for a list of approved ingresses before provisioning ALBs with an internet-facing scheme. Here is an example of that ConfigMap: apiVersion : v1 data : mynamespace : my-ingress-name, my-ingress-name-2 myothernamespace : my-other-ingress-name kind : ConfigMap metadata : name : alb-ingress-controller-internet-facing-ingresses This ConfigMap is kept in default if unspecified, and can be overridden via the --restrict-scheme-namespace flag. Resource Tags \u00b6 Setting the --default-tags argument adds arbitrary tags to ALBs and target groups managed by the ingress controller. spec : containers : - args : - /server - --default-tags=mykey=myvalue,otherkey=othervalue Subnet Auto Discovery \u00b6 You can tag AWS subnets to allow ingress controller auto discover subnets used for ALBs. kubernetes.io/cluster/ ${ cluster - name } must be set to owned or shared kubernetes.io/role/internal-elb must be set to 1 or `` for internal LoadBalancers kubernetes.io/role/elb must be set to 1 or `` for internet-facing LoadBalancers An example of a subnet with the correct tags for the cluster joshcalico is as follows:","title":"Configuration"},{"location":"guide/controller/config/#alb-ingress-controller-configuration","text":"This document covers configuration of the ALB ingress controller","title":"ALB Ingress Controller Configuration"},{"location":"guide/controller/config/#aws-api-access","text":"To perform operations, the controller must have required IAM role capabilities for accessing and provisioning ALB resources. There are many ways to achieve this, such as loading AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY as environment variables or using kube2iam . A sample IAM policy, with the minimum permissions to run the controller, can be found in alb-iam-policy.json .","title":"AWS API Access"},{"location":"guide/controller/config/#setting-ingress-resource-scope","text":"You can limit the ingresses ALB ingress controller controls by combining following two approaches:","title":"Setting Ingress Resource Scope"},{"location":"guide/controller/config/#limiting-ingress-class","text":"Setting the --ingress-class argument constrains the controller's scope to ingresses with matching kubernetes.io/ingress.class annotation. This is especially helpful when running multiple ingress controllers in the same cluster. See Using Multiple Ingress Controllers for more details. An example of the container spec portion of the controller, only listening for resources with the class \"alb\", would be as follows. spec : containers : - args : - --ingress-class=alb Now, only ingress resources with the appropriate annotation are picked up, as seen below. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : echoserver namespace : echoserver annotations : kubernetes.io/ingress.class : \"alb\" spec : ...","title":"Limiting ingress class"},{"location":"guide/controller/config/#limiting-namespaces","text":"Setting the --watch-namespace argument constrains the controller's scope to a single namespace. Ingress events outside of the namespace specified are not be seen by the controller. An example of the container spec, for a controller watching only the default namespace, is as follows. spec : containers : - args : - --watch-namespace=default Currently, you can set only 1 namespace to watch in this flag. See this Kubernetes issue for more details.","title":"Limiting Namespaces"},{"location":"guide/controller/config/#limiting-external-namespaces","text":"Setting the --restrict-scheme boolean flag to true will enable the ALB controller to check the configmap named alb-ingress-controller-internet-facing-ingresses for a list of approved ingresses before provisioning ALBs with an internet-facing scheme. Here is an example of that ConfigMap: apiVersion : v1 data : mynamespace : my-ingress-name, my-ingress-name-2 myothernamespace : my-other-ingress-name kind : ConfigMap metadata : name : alb-ingress-controller-internet-facing-ingresses This ConfigMap is kept in default if unspecified, and can be overridden via the --restrict-scheme-namespace flag.","title":"Limiting External Namespaces"},{"location":"guide/controller/config/#resource-tags","text":"Setting the --default-tags argument adds arbitrary tags to ALBs and target groups managed by the ingress controller. spec : containers : - args : - /server - --default-tags=mykey=myvalue,otherkey=othervalue","title":"Resource Tags"},{"location":"guide/controller/config/#subnet-auto-discovery","text":"You can tag AWS subnets to allow ingress controller auto discover subnets used for ALBs. kubernetes.io/cluster/ ${ cluster - name } must be set to owned or shared kubernetes.io/role/internal-elb must be set to 1 or `` for internal LoadBalancers kubernetes.io/role/elb must be set to 1 or `` for internet-facing LoadBalancers An example of a subnet with the correct tags for the cluster joshcalico is as follows:","title":"Subnet Auto Discovery"},{"location":"guide/controller/how-it-works/","text":"How ALB ingress controller works \u00b6 Design \u00b6 The following diagram details the AWS components this controller creates. It also demonstrates the route ingress traffic takes from the ALB to the Kubernetes cluster. Ingress Creation \u00b6 This section describes each step (circle) above. This example demonstrates satisfying 1 ingress resource. [1] : The controller watches for ingress events from the API server. When it finds ingress resources that satisfy its requirements, it begins the creation of AWS resources. [2] : An ALB (ELBv2) is created in AWS for the new ingress resource. This ALB can be internet-facing or internal. You can also specify the subnets it's created in using annotations. [3] : Target Groups are created in AWS for each unique Kubernetes service described in the ingress resource. [4] : Listeners are created for every port detailed in your ingress resource annotations. When no port is specified, sensible defaults ( 80 or 443 ) are used. Certificates may also be attached via annotations. [5] : Rules are created for each path specified in your ingress resource. This ensures traffic to a specific path is routed to the correct Kubernetes Service. Along with the above, the controller also... deletes AWS components when ingress resources are removed from k8s. modifies AWS components when ingress resources change in k8s. assembles a list of existing ingress-related AWS components on start-up, allowing you to recover if the controller were to be restarted. Ingress Traffic \u00b6 ALB Ingress controller supports two traffic modes: Instance mode IP mode By default, Instance mode is used, users can explicitly select the mode via alb.ingress.kubernetes.io/target-type annotation. Instance mode \u00b6 Ingress traffic starts at the ALB and reaches the Kubernetes nodes through each service's NodePort. This means that services referenced from ingress resources must be exposed by type : NodePort in order to be reached by the ALB. IP mode \u00b6 Ingress traffic starts at the ALB and reaches the Kubernetes pods directly. CNIs must support directly accessible POD ip via secondary IP addresses on ENI .","title":"How it works"},{"location":"guide/controller/how-it-works/#how-alb-ingress-controller-works","text":"","title":"How ALB ingress controller works"},{"location":"guide/controller/how-it-works/#design","text":"The following diagram details the AWS components this controller creates. It also demonstrates the route ingress traffic takes from the ALB to the Kubernetes cluster.","title":"Design"},{"location":"guide/controller/how-it-works/#ingress-creation","text":"This section describes each step (circle) above. This example demonstrates satisfying 1 ingress resource. [1] : The controller watches for ingress events from the API server. When it finds ingress resources that satisfy its requirements, it begins the creation of AWS resources. [2] : An ALB (ELBv2) is created in AWS for the new ingress resource. This ALB can be internet-facing or internal. You can also specify the subnets it's created in using annotations. [3] : Target Groups are created in AWS for each unique Kubernetes service described in the ingress resource. [4] : Listeners are created for every port detailed in your ingress resource annotations. When no port is specified, sensible defaults ( 80 or 443 ) are used. Certificates may also be attached via annotations. [5] : Rules are created for each path specified in your ingress resource. This ensures traffic to a specific path is routed to the correct Kubernetes Service. Along with the above, the controller also... deletes AWS components when ingress resources are removed from k8s. modifies AWS components when ingress resources change in k8s. assembles a list of existing ingress-related AWS components on start-up, allowing you to recover if the controller were to be restarted.","title":"Ingress Creation"},{"location":"guide/controller/how-it-works/#ingress-traffic","text":"ALB Ingress controller supports two traffic modes: Instance mode IP mode By default, Instance mode is used, users can explicitly select the mode via alb.ingress.kubernetes.io/target-type annotation.","title":"Ingress Traffic"},{"location":"guide/controller/how-it-works/#instance-mode","text":"Ingress traffic starts at the ALB and reaches the Kubernetes nodes through each service's NodePort. This means that services referenced from ingress resources must be exposed by type : NodePort in order to be reached by the ALB.","title":"Instance mode"},{"location":"guide/controller/how-it-works/#ip-mode","text":"Ingress traffic starts at the ALB and reaches the Kubernetes pods directly. CNIs must support directly accessible POD ip via secondary IP addresses on ENI .","title":"IP mode"},{"location":"guide/controller/setup/","text":"Setup ALB ingress controller \u00b6 This document describes how to install ALB ingress controller into your kubernetes cluster on AWS. If you'd prefer an end-to-end walkthrough of setup instead, see the echoservice walkthrough Prerequisites \u00b6 This section details what must be setup in order for the controller to run. Kubelet \u00b6 The kubelet must be run with --cloud-provider=aws . This populates the EC2 instance ID in each node's spec. Role Permissions \u00b6 Adequate roles and policies must be configured in AWS and available to the node(s) running the controller. How access is granted is up to you. Some will attach the needed rights to node's role in AWS. Others will use projects like kube2iam . An example policy with the minimum rights can be found at iam-policy.json . Installation \u00b6 You can choose to install ALB ingress controller via Helm or Kubectl Helm \u00b6 Install Helm App Registry plugin Install ALB ingress controller helm registry install quay.io/coreos/alb-ingress-controller-helm Kubectl \u00b6 Download sample ALB ingress controller manifest wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/alb-ingress-controller.yaml Configure the ALB ingress controller manifest At minimum, edit the following variables: --cluster-name=devCluster : name of the cluster. AWS resources will be tagged with kubernetes.io/cluster/devCluster:owned Tip If ec2metadata is unavailable from the controller pod, edit the following variables: --aws-vpc-id=vpc-xxxxxx : vpc ID of the cluster. --aws-region=us-west-1 : AWS region of the cluster. Deploy the RBAC roles manifest kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/rbac-role.yaml Deploy the ALB ingress controller manifest kubectl apply -f alb-ingress-controller.yaml Verify the deployment was successful and the controller started kubectl logs -n kube-system $( kubectl get po -n kube-system | egrep -o alb-ingress [ a-zA-Z0-9- ] + ) Should display output similar to the following. ------------------------------------------------------------------------------- AWS ALB Ingress controller Release: 1.0.0 Build: git-7bc1850b Repository: https://github.com/kubernetes-sigs/aws-alb-ingress-controller.git -------------------------------------------------------------------------------","title":"Setup"},{"location":"guide/controller/setup/#setup-alb-ingress-controller","text":"This document describes how to install ALB ingress controller into your kubernetes cluster on AWS. If you'd prefer an end-to-end walkthrough of setup instead, see the echoservice walkthrough","title":"Setup ALB ingress controller"},{"location":"guide/controller/setup/#prerequisites","text":"This section details what must be setup in order for the controller to run.","title":"Prerequisites"},{"location":"guide/controller/setup/#kubelet","text":"The kubelet must be run with --cloud-provider=aws . This populates the EC2 instance ID in each node's spec.","title":"Kubelet"},{"location":"guide/controller/setup/#role-permissions","text":"Adequate roles and policies must be configured in AWS and available to the node(s) running the controller. How access is granted is up to you. Some will attach the needed rights to node's role in AWS. Others will use projects like kube2iam . An example policy with the minimum rights can be found at iam-policy.json .","title":"Role Permissions"},{"location":"guide/controller/setup/#installation","text":"You can choose to install ALB ingress controller via Helm or Kubectl","title":"Installation"},{"location":"guide/controller/setup/#helm","text":"Install Helm App Registry plugin Install ALB ingress controller helm registry install quay.io/coreos/alb-ingress-controller-helm","title":"Helm"},{"location":"guide/controller/setup/#kubectl","text":"Download sample ALB ingress controller manifest wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/alb-ingress-controller.yaml Configure the ALB ingress controller manifest At minimum, edit the following variables: --cluster-name=devCluster : name of the cluster. AWS resources will be tagged with kubernetes.io/cluster/devCluster:owned Tip If ec2metadata is unavailable from the controller pod, edit the following variables: --aws-vpc-id=vpc-xxxxxx : vpc ID of the cluster. --aws-region=us-west-1 : AWS region of the cluster. Deploy the RBAC roles manifest kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/rbac-role.yaml Deploy the ALB ingress controller manifest kubectl apply -f alb-ingress-controller.yaml Verify the deployment was successful and the controller started kubectl logs -n kube-system $( kubectl get po -n kube-system | egrep -o alb-ingress [ a-zA-Z0-9- ] + ) Should display output similar to the following. ------------------------------------------------------------------------------- AWS ALB Ingress controller Release: 1.0.0 Build: git-7bc1850b Repository: https://github.com/kubernetes-sigs/aws-alb-ingress-controller.git -------------------------------------------------------------------------------","title":"Kubectl"},{"location":"guide/external-dns/setup/","text":"Setup External DNS \u00b6 external-dns provisions DNS records based on the host information. This project will setup and manage records in Route 53 that point to controller deployed ALBs. Prerequisites \u00b6 Role Permissions \u00b6 Adequate roles and policies must be configured in AWS and available to the node(s) running the external-dns. See https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/aws.md#iam-permissions. Installation \u00b6 Download sample external-dns manifest wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/external-dns.yaml Edit the --domain-filter flag to include your hosted zone(s) The following example is for a hosted zone test-dns.com args : - --source=service - --source=ingress - --domain-filter=test-dns.com # will make ExternalDNS see only the hosted zones matching provided domain, omit to process all available hosted zones - --provider=aws - --policy=upsert-only # would prevent ExternalDNS from deleting any records, omit to enable full synchronization Deploy external-dns kubectl apply -f external-dns.yaml Verify it deployed successfully. kubectl logs -f -n kube-system $( kubectl get po -n kube-system | egrep -o 'external-dns[A-Za-z0-9-]+' ) Should display output similar to the following. time = \"2017-09-19T02:51:54Z\" level = info msg = \"config: &{Master: KubeConfig: Sources:[service ingress] Namespace: FQDNTemplate: Compatibility: Provider:aws GoogleProject: DomainFilter:[] AzureConfigFile:/etc/kuberne tes/azure.json AzureResourceGroup: Policy:upsert-only Registry:txt TXTOwnerID:my-identifier TXTPrefix: Interval:1m0s Once:false DryRun:false LogFormat:text MetricsAddress::7979 Debug:false}\" time = \"2017-09-19T02:51:54Z\" level = info msg = \"Connected to cluster at https://10.3.0.1:443\"","title":"Setup"},{"location":"guide/external-dns/setup/#setup-external-dns","text":"external-dns provisions DNS records based on the host information. This project will setup and manage records in Route 53 that point to controller deployed ALBs.","title":"Setup External DNS"},{"location":"guide/external-dns/setup/#prerequisites","text":"","title":"Prerequisites"},{"location":"guide/external-dns/setup/#role-permissions","text":"Adequate roles and policies must be configured in AWS and available to the node(s) running the external-dns. See https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/aws.md#iam-permissions.","title":"Role Permissions"},{"location":"guide/external-dns/setup/#installation","text":"Download sample external-dns manifest wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/external-dns.yaml Edit the --domain-filter flag to include your hosted zone(s) The following example is for a hosted zone test-dns.com args : - --source=service - --source=ingress - --domain-filter=test-dns.com # will make ExternalDNS see only the hosted zones matching provided domain, omit to process all available hosted zones - --provider=aws - --policy=upsert-only # would prevent ExternalDNS from deleting any records, omit to enable full synchronization Deploy external-dns kubectl apply -f external-dns.yaml Verify it deployed successfully. kubectl logs -f -n kube-system $( kubectl get po -n kube-system | egrep -o 'external-dns[A-Za-z0-9-]+' ) Should display output similar to the following. time = \"2017-09-19T02:51:54Z\" level = info msg = \"config: &{Master: KubeConfig: Sources:[service ingress] Namespace: FQDNTemplate: Compatibility: Provider:aws GoogleProject: DomainFilter:[] AzureConfigFile:/etc/kuberne tes/azure.json AzureResourceGroup: Policy:upsert-only Registry:txt TXTOwnerID:my-identifier TXTPrefix: Interval:1m0s Once:false DryRun:false LogFormat:text MetricsAddress::7979 Debug:false}\" time = \"2017-09-19T02:51:54Z\" level = info msg = \"Connected to cluster at https://10.3.0.1:443\"","title":"Installation"},{"location":"guide/ingress/annotation/","text":"Ingress annotations \u00b6 You can add kubernetes annotations to ingress and service objects to customize their behavior. Note Annotations applied to service have higher priority over annotations applied to ingress. Location column below indicates where that annotation can be applied to. Annotation keys and values can only be strings. Advanced format are encoded as below: stringMap: k1=v1,k2=v2 stringList: s1,s2,s3 json: 'jsonContent' Tip The annotation prefix can be changed using the --annotations-prefix command line argument, by default it's alb.ingress.kubernetes.io , as described in the table below. Annotations \u00b6 Name Type Default Location alb.ingress.kubernetes.io/actions.${action-name} json N/A ingress alb.ingress.kubernetes.io/backend-protocol HTTP | HTTPS HTTP ingress,service alb.ingress.kubernetes.io/certificate-arn string N/A ingress alb.ingress.kubernetes.io/healthcheck-interval-seconds integer 15 ingress,service alb.ingress.kubernetes.io/healthcheck-path string / ingress,service alb.ingress.kubernetes.io/healthcheck-port integer | traffic-port traffic-port ingress,service alb.ingress.kubernetes.io/healthcheck-protocol HTTP | HTTPS HTTP ingress,service alb.ingress.kubernetes.io/healthcheck-timeout-seconds integer 5 ingress,service alb.ingress.kubernetes.io/healthy-threshold-count integer 2 ingress,service alb.ingress.kubernetes.io/inbound-cidrs stringList 0.0.0.0/0 ingress alb.ingress.kubernetes.io/ip-address-type ipv4 | dualstack ipv4 ingress alb.ingress.kubernetes.io/listen-ports json '[{\"HTTP\": 80}]' | '[{\"HTTPS\": 443}]' ingress alb.ingress.kubernetes.io/load-balancer-attributes stringMap N/A ingress alb.ingress.kubernetes.io/scheme internal | internet-facing internal ingress alb.ingress.kubernetes.io/security-groups stringList N/A ingress alb.ingress.kubernetes.io/ssl-policy string ELBSecurityPolicy-2016-08 ingress alb.ingress.kubernetes.io/subnets stringList N/A ingress alb.ingress.kubernetes.io/success-codes string 200 ingress alb.ingress.kubernetes.io/tags stringMap N/A ingress alb.ingress.kubernetes.io/target-group-attributes stringMap N/A ingress alb.ingress.kubernetes.io/target-type instance | ip instance ingress,service alb.ingress.kubernetes.io/unhealthy-threshold-count integer 2 ingress,service Traffic Listening \u00b6 Traffic Listening can be controlled with following annotations: alb.ingress.kubernetes.io/listen-ports specifies the ports that ALB used to listen on. defaults to '[{\"HTTP\": 80}]' or '[{\"HTTPS\": 443}]' depends on whether certificate-arn is specified. Example alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}, {\"HTTP\": 8080}, {\"HTTPS\": 8443}]' alb.ingress.kubernetes.io/ip-address-type specifies the IP address type of ALB. Example alb.ingress.kubernetes.io/ip-address-type: ipv4 Traffic Routing \u00b6 Traffic Routing can be controlled with following annotations: alb.ingress.kubernetes.io/target-type specifies how to route traffic to pods. You can choose between instance and ip : instance mode will route traffic to all ec2 instances within cluster on NodePort opened for your service. service must be of type \"NodePort\" or \"LoadBalancer\" to use instance mode ip mode will route traffic directly to the pod IP. network plugin must use secondary IP addresses on ENI for pod IP to use ip mode. e.g. amazon-vpc-cni-k8s Example alb.ingress.kubernetes.io/target-type: instance alb.ingress.kubernetes.io/backend-protocol specifies the protocol used when route traffic to pods. Example alb.ingress.kubernetes.io/backend-protocol: HTTPS alb.ingress.kubernetes.io/subnets specifies the Availability Zone that ALB will route traffic to. See Load Balancer subnets for more details. You must specify at least two subnets in different AZ. both subnetID or subnetName(Name tag on subnets) can be used. Tip You can enable subnet auto discovery to avoid specify this annotation on every ingress. See Subnet Auto Discovery for instructions. Example alb.ingress.kubernetes.io/subnets: subnet-xxxx, mySubnet alb.ingress.kubernetes.io/actions. ${ action - name } Provides a method for configuring custom actions on a listener, such as for Redirect Actions. The action-name in the annotation must match the serviceName in the ingress rules, and servicePort must be use-annotation . Example fixed 503 response apiVersion : extensions/v1beta1 kind : Ingress metadata : namespace : default name : ingress annotations : kubernetes.io/ingress.class : alb alb.ingress.kubernetes.io/actions.response-503 : '{\"Type\": \"fixed-response\", \"FixedResponseConfig\": {\"ContentType\":\"text/plain\", \"StatusCode\":\"503\", \"MessageBody\":\"503 error text\"}}' spec : rules : - http : paths : - path : /503 backend : serviceName : response-503 servicePort : use-annotation Access control \u00b6 Access control for LoadBalancer can be controlled with following annotations: alb.ingress.kubernetes.io/scheme specifies whether your LoadBalancer will be internet facing. See Load balancer scheme in the AWS documentation for more details. Example alb.ingress.kubernetes.io/scheme: internal alb.ingress.kubernetes.io/inbound-cidrs specifies the CIDRs that are allowed to access LoadBalancer. this annotation will be ignored if alb.ingress.kubernetes.io/security-groups is specified. Example alb.ingress.kubernetes.io/inbound-cidrs: 10.0.0.0/24 alb.ingress.kubernetes.io/security-groups specifies the securityGroups you want to attach to LoadBalancer. both name or ID of securityGroups are supported. if this annotation is specified, you should also manage securityGroup on nodes to allow inbound traffic from LoadBalancer. Example alb.ingress.kubernetes.io/security-groups: sg-xxxx, nameOfSg1, nameOfSg2 Health Check \u00b6 Health check on target groups can be controlled with following annotations: alb.ingress.kubernetes.io/healthcheck-protocol specifies the protocol used when performing health check on targets. default protocol can be set via --backend-protocol flag Example alb.ingress.kubernetes.io/healthcheck-protocol: HTTPS alb.ingress.kubernetes.io/healthcheck-port specifies the port used when performing health check on targets. Example alb.ingress.kubernetes.io/healthcheck-port: traffic-port alb.ingress.kubernetes.io/healthcheck-port: 80 alb.ingress.kubernetes.io/healthcheck-path specifies the HTTP path when peforming health check on targets. Example alb.ingress.kubernetes.io/healthcheck-path: /ping alb.ingress.kubernetes.io/healthcheck-interval-seconds specifies the interval(in seconds) between health check of an individual target. Example alb.ingress.kubernetes.io/healthcheck-interval-seconds: 10 alb.ingress.kubernetes.io/healthcheck-timeout-seconds specifies the timeout(in seconds) during which no response from a target means a failed health check Example alb.ingress.kubernetes.io/healthcheck-timeout-seconds: 8 alb.ingress.kubernetes.io/success-codes specifies the HTTP status code that should be expected when doing health checks against the specified health check path. Example use multiple values alb.ingress.kubernetes.io/success-codes: 200,201 use range of value alb.ingress.kubernetes.io/success-codes: 200-300 alb.ingress.kubernetes.io/healthy-threshold-count specifies the consecutive health checks successes required before considering an unhealthy target healthy. Example alb.ingress.kubernetes.io/healthy-threshold-count: 2 alb.ingress.kubernetes.io/unhealthy-threshold-count specifies the consecutive health check failures required before considering a target unhealthy. Example alb.ingress.kubernetes.io/unhealthy-threshold-count: 2 SSL \u00b6 SSL support can be controlled with following annotations: alb.ingress.kubernetes.io/certificate-arn specifies the ARN of certificate managed by AWS Certificate Manager Example alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-west-2:xxxxx:certificate/xxxxxxx alb.ingress.kubernetes.io/ssl-policy specifies the Security Policy that should be assigned to the ALB, allowing you to control the protocol and ciphers. Example alb.ingress.kubernetes.io/ssl-policy: ELBSecurityPolicy-TLS-1-1-2017-01 Custom attributes \u00b6 Custom attributes to LoadBalancers and TargetGroups can be controlled with following annotations: alb.ingress.kubernetes.io/load-balancer-attributes specifies Load Balancer Attributes that should be applied to the ALB. Example enable access log to s3 alb.ingress.kubernetes.io/load-balancer-attributes:access_logs.s3.enabled=true,access_logs.s3.bucket=my-access-log-bucket,access_logs.s3.prefix=my-app enable deletion protection alb.ingress.kubernetes.io/load-balancer-attributes:deletion_protection.enabled=true enable http2 support alb.ingress.kubernetes.io/load-balancer-attributes:routing.http2.enabled=true alb.ingress.kubernetes.io/target-group-attributes specifies Target Group Attributes which should be applied to Target Groups. Example alb.ingress.kubernetes.io/target-group-attributes: slow_start.duration_seconds=5 Resource Tags \u00b6 ALB Ingress controller will automatically apply following tags to AWS resources(ALB/TargetGroups/SecurityGroups) created. kubernetes.io/cluster/ ${ cluster - name } :owned kubernetes.io/namespace: ${ namespace } kubernetes.io/ingress-name: ${ ingress - name } In addition, you can use annotations to specify additional tags alb.ingress.kubernetes.io/tags specifies additional tags that will be applied to AWS resources created. Example alb.ingress.kubernetes.io/tags: Environment=dev,Team=test","title":"Annotation"},{"location":"guide/ingress/annotation/#ingress-annotations","text":"You can add kubernetes annotations to ingress and service objects to customize their behavior. Note Annotations applied to service have higher priority over annotations applied to ingress. Location column below indicates where that annotation can be applied to. Annotation keys and values can only be strings. Advanced format are encoded as below: stringMap: k1=v1,k2=v2 stringList: s1,s2,s3 json: 'jsonContent' Tip The annotation prefix can be changed using the --annotations-prefix command line argument, by default it's alb.ingress.kubernetes.io , as described in the table below.","title":"Ingress annotations"},{"location":"guide/ingress/annotation/#annotations","text":"Name Type Default Location alb.ingress.kubernetes.io/actions.${action-name} json N/A ingress alb.ingress.kubernetes.io/backend-protocol HTTP | HTTPS HTTP ingress,service alb.ingress.kubernetes.io/certificate-arn string N/A ingress alb.ingress.kubernetes.io/healthcheck-interval-seconds integer 15 ingress,service alb.ingress.kubernetes.io/healthcheck-path string / ingress,service alb.ingress.kubernetes.io/healthcheck-port integer | traffic-port traffic-port ingress,service alb.ingress.kubernetes.io/healthcheck-protocol HTTP | HTTPS HTTP ingress,service alb.ingress.kubernetes.io/healthcheck-timeout-seconds integer 5 ingress,service alb.ingress.kubernetes.io/healthy-threshold-count integer 2 ingress,service alb.ingress.kubernetes.io/inbound-cidrs stringList 0.0.0.0/0 ingress alb.ingress.kubernetes.io/ip-address-type ipv4 | dualstack ipv4 ingress alb.ingress.kubernetes.io/listen-ports json '[{\"HTTP\": 80}]' | '[{\"HTTPS\": 443}]' ingress alb.ingress.kubernetes.io/load-balancer-attributes stringMap N/A ingress alb.ingress.kubernetes.io/scheme internal | internet-facing internal ingress alb.ingress.kubernetes.io/security-groups stringList N/A ingress alb.ingress.kubernetes.io/ssl-policy string ELBSecurityPolicy-2016-08 ingress alb.ingress.kubernetes.io/subnets stringList N/A ingress alb.ingress.kubernetes.io/success-codes string 200 ingress alb.ingress.kubernetes.io/tags stringMap N/A ingress alb.ingress.kubernetes.io/target-group-attributes stringMap N/A ingress alb.ingress.kubernetes.io/target-type instance | ip instance ingress,service alb.ingress.kubernetes.io/unhealthy-threshold-count integer 2 ingress,service","title":"Annotations"},{"location":"guide/ingress/annotation/#traffic-listening","text":"Traffic Listening can be controlled with following annotations: alb.ingress.kubernetes.io/listen-ports specifies the ports that ALB used to listen on. defaults to '[{\"HTTP\": 80}]' or '[{\"HTTPS\": 443}]' depends on whether certificate-arn is specified. Example alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}, {\"HTTP\": 8080}, {\"HTTPS\": 8443}]' alb.ingress.kubernetes.io/ip-address-type specifies the IP address type of ALB. Example alb.ingress.kubernetes.io/ip-address-type: ipv4","title":"Traffic Listening"},{"location":"guide/ingress/annotation/#traffic-routing","text":"Traffic Routing can be controlled with following annotations: alb.ingress.kubernetes.io/target-type specifies how to route traffic to pods. You can choose between instance and ip : instance mode will route traffic to all ec2 instances within cluster on NodePort opened for your service. service must be of type \"NodePort\" or \"LoadBalancer\" to use instance mode ip mode will route traffic directly to the pod IP. network plugin must use secondary IP addresses on ENI for pod IP to use ip mode. e.g. amazon-vpc-cni-k8s Example alb.ingress.kubernetes.io/target-type: instance alb.ingress.kubernetes.io/backend-protocol specifies the protocol used when route traffic to pods. Example alb.ingress.kubernetes.io/backend-protocol: HTTPS alb.ingress.kubernetes.io/subnets specifies the Availability Zone that ALB will route traffic to. See Load Balancer subnets for more details. You must specify at least two subnets in different AZ. both subnetID or subnetName(Name tag on subnets) can be used. Tip You can enable subnet auto discovery to avoid specify this annotation on every ingress. See Subnet Auto Discovery for instructions. Example alb.ingress.kubernetes.io/subnets: subnet-xxxx, mySubnet alb.ingress.kubernetes.io/actions. ${ action - name } Provides a method for configuring custom actions on a listener, such as for Redirect Actions. The action-name in the annotation must match the serviceName in the ingress rules, and servicePort must be use-annotation . Example fixed 503 response apiVersion : extensions/v1beta1 kind : Ingress metadata : namespace : default name : ingress annotations : kubernetes.io/ingress.class : alb alb.ingress.kubernetes.io/actions.response-503 : '{\"Type\": \"fixed-response\", \"FixedResponseConfig\": {\"ContentType\":\"text/plain\", \"StatusCode\":\"503\", \"MessageBody\":\"503 error text\"}}' spec : rules : - http : paths : - path : /503 backend : serviceName : response-503 servicePort : use-annotation","title":"Traffic Routing"},{"location":"guide/ingress/annotation/#access-control","text":"Access control for LoadBalancer can be controlled with following annotations: alb.ingress.kubernetes.io/scheme specifies whether your LoadBalancer will be internet facing. See Load balancer scheme in the AWS documentation for more details. Example alb.ingress.kubernetes.io/scheme: internal alb.ingress.kubernetes.io/inbound-cidrs specifies the CIDRs that are allowed to access LoadBalancer. this annotation will be ignored if alb.ingress.kubernetes.io/security-groups is specified. Example alb.ingress.kubernetes.io/inbound-cidrs: 10.0.0.0/24 alb.ingress.kubernetes.io/security-groups specifies the securityGroups you want to attach to LoadBalancer. both name or ID of securityGroups are supported. if this annotation is specified, you should also manage securityGroup on nodes to allow inbound traffic from LoadBalancer. Example alb.ingress.kubernetes.io/security-groups: sg-xxxx, nameOfSg1, nameOfSg2","title":"Access control"},{"location":"guide/ingress/annotation/#health-check","text":"Health check on target groups can be controlled with following annotations: alb.ingress.kubernetes.io/healthcheck-protocol specifies the protocol used when performing health check on targets. default protocol can be set via --backend-protocol flag Example alb.ingress.kubernetes.io/healthcheck-protocol: HTTPS alb.ingress.kubernetes.io/healthcheck-port specifies the port used when performing health check on targets. Example alb.ingress.kubernetes.io/healthcheck-port: traffic-port alb.ingress.kubernetes.io/healthcheck-port: 80 alb.ingress.kubernetes.io/healthcheck-path specifies the HTTP path when peforming health check on targets. Example alb.ingress.kubernetes.io/healthcheck-path: /ping alb.ingress.kubernetes.io/healthcheck-interval-seconds specifies the interval(in seconds) between health check of an individual target. Example alb.ingress.kubernetes.io/healthcheck-interval-seconds: 10 alb.ingress.kubernetes.io/healthcheck-timeout-seconds specifies the timeout(in seconds) during which no response from a target means a failed health check Example alb.ingress.kubernetes.io/healthcheck-timeout-seconds: 8 alb.ingress.kubernetes.io/success-codes specifies the HTTP status code that should be expected when doing health checks against the specified health check path. Example use multiple values alb.ingress.kubernetes.io/success-codes: 200,201 use range of value alb.ingress.kubernetes.io/success-codes: 200-300 alb.ingress.kubernetes.io/healthy-threshold-count specifies the consecutive health checks successes required before considering an unhealthy target healthy. Example alb.ingress.kubernetes.io/healthy-threshold-count: 2 alb.ingress.kubernetes.io/unhealthy-threshold-count specifies the consecutive health check failures required before considering a target unhealthy. Example alb.ingress.kubernetes.io/unhealthy-threshold-count: 2","title":"Health Check"},{"location":"guide/ingress/annotation/#ssl","text":"SSL support can be controlled with following annotations: alb.ingress.kubernetes.io/certificate-arn specifies the ARN of certificate managed by AWS Certificate Manager Example alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-west-2:xxxxx:certificate/xxxxxxx alb.ingress.kubernetes.io/ssl-policy specifies the Security Policy that should be assigned to the ALB, allowing you to control the protocol and ciphers. Example alb.ingress.kubernetes.io/ssl-policy: ELBSecurityPolicy-TLS-1-1-2017-01","title":"SSL"},{"location":"guide/ingress/annotation/#custom-attributes","text":"Custom attributes to LoadBalancers and TargetGroups can be controlled with following annotations: alb.ingress.kubernetes.io/load-balancer-attributes specifies Load Balancer Attributes that should be applied to the ALB. Example enable access log to s3 alb.ingress.kubernetes.io/load-balancer-attributes:access_logs.s3.enabled=true,access_logs.s3.bucket=my-access-log-bucket,access_logs.s3.prefix=my-app enable deletion protection alb.ingress.kubernetes.io/load-balancer-attributes:deletion_protection.enabled=true enable http2 support alb.ingress.kubernetes.io/load-balancer-attributes:routing.http2.enabled=true alb.ingress.kubernetes.io/target-group-attributes specifies Target Group Attributes which should be applied to Target Groups. Example alb.ingress.kubernetes.io/target-group-attributes: slow_start.duration_seconds=5","title":"Custom attributes"},{"location":"guide/ingress/annotation/#resource-tags","text":"ALB Ingress controller will automatically apply following tags to AWS resources(ALB/TargetGroups/SecurityGroups) created. kubernetes.io/cluster/ ${ cluster - name } :owned kubernetes.io/namespace: ${ namespace } kubernetes.io/ingress-name: ${ ingress - name } In addition, you can use annotations to specify additional tags alb.ingress.kubernetes.io/tags specifies additional tags that will be applied to AWS resources created. Example alb.ingress.kubernetes.io/tags: Environment=dev,Team=test","title":"Resource Tags"},{"location":"guide/ingress/spec/","text":"Ingress specification \u00b6 This document covers how ingress resources work in relation to The ALB Ingress Controller. An example ingress, from example is as follows. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : \"nginx-ingress\" namespace : \"2048-game\" annotations : kubernetes.io/ingress.class : alb labels : app : 2048-nginx-ingress spec : rules : - host : 2048.example.com http : paths : - path : / backend : serviceName : \"service-2048\" servicePort : 80 The host field specifies the eventual Route 53-managed domain that will route to this service. The service, service-2048, must be of type NodePort in order for the provisioned ALB to route to it.(see echoserver-service.yaml ) For details on purpose of annotations seen above, see Annotations .","title":"Spec"},{"location":"guide/ingress/spec/#ingress-specification","text":"This document covers how ingress resources work in relation to The ALB Ingress Controller. An example ingress, from example is as follows. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : \"nginx-ingress\" namespace : \"2048-game\" annotations : kubernetes.io/ingress.class : alb labels : app : 2048-nginx-ingress spec : rules : - host : 2048.example.com http : paths : - path : / backend : serviceName : \"service-2048\" servicePort : 80 The host field specifies the eventual Route 53-managed domain that will route to this service. The service, service-2048, must be of type NodePort in order for the provisioned ALB to route to it.(see echoserver-service.yaml ) For details on purpose of annotations seen above, see Annotations .","title":"Ingress specification"},{"location":"guide/tasks/ssl_redirect/","text":"Redirect Traffic from HTTP to HTTPS \u00b6 We'll use the alb.ingress.kubernetes.io/actions. ${ action - name } annotation to setup an ingress to redirect http traffic into https Example Ingress Manifest \u00b6 apiVersion : extensions/v1beta1 kind : Ingress metadata : namespace : default name : ingress annotations : kubernetes.io/ingress.class : alb alb.ingress.kubernetes.io/certificate-arn : arn:aws:acm:us-west-2:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen-ports : '[{\"HTTP\": 80}, {\"HTTPS\":443}]' alb.ingress.kubernetes.io/actions.ssl-redirect : '{\"Type\": \"redirect\", \"RedirectConfig\": { \"Protocol\": \"HTTPS\", \"Port\": \"443\", \"StatusCode\": \"HTTP_301\"}}' spec : rules : - http : paths : - path : /* backend : serviceName : ssl-redirect servicePort : use-annotation - path : /users/* backend : serviceName : user-service servicePort : 80 - path : /* backend : serviceName : default-service servicePort : 80 Note alb.ingress.kubernetes.io/listen-ports annotation must at least include [{\"HTTP\": 80}, {\"HTTPS\":443}] to listen on 80 and 443. alb.ingress.kubernetes.io/certificate-arn annotation must be set to allow listen for HTTPS traffic the ssl-redirect action must be be first rule(which will be evaluated first by ALB) How it works \u00b6 By default, all rules specified in ingress spec will be applied to all listeners(one listener per port) on ALB. If there is an redirection rule, the ALB ingress controller will check it against every listener(port) to see whether it will introduce infinite redirection loop, and will ignore that rule for specific listener. So for our above example, the rule by ssl-redirect will only been applied to http(80) listener.","title":"SSL Redirect"},{"location":"guide/tasks/ssl_redirect/#redirect-traffic-from-http-to-https","text":"We'll use the alb.ingress.kubernetes.io/actions. ${ action - name } annotation to setup an ingress to redirect http traffic into https","title":"Redirect Traffic from HTTP to HTTPS"},{"location":"guide/tasks/ssl_redirect/#example-ingress-manifest","text":"apiVersion : extensions/v1beta1 kind : Ingress metadata : namespace : default name : ingress annotations : kubernetes.io/ingress.class : alb alb.ingress.kubernetes.io/certificate-arn : arn:aws:acm:us-west-2:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen-ports : '[{\"HTTP\": 80}, {\"HTTPS\":443}]' alb.ingress.kubernetes.io/actions.ssl-redirect : '{\"Type\": \"redirect\", \"RedirectConfig\": { \"Protocol\": \"HTTPS\", \"Port\": \"443\", \"StatusCode\": \"HTTP_301\"}}' spec : rules : - http : paths : - path : /* backend : serviceName : ssl-redirect servicePort : use-annotation - path : /users/* backend : serviceName : user-service servicePort : 80 - path : /* backend : serviceName : default-service servicePort : 80 Note alb.ingress.kubernetes.io/listen-ports annotation must at least include [{\"HTTP\": 80}, {\"HTTPS\":443}] to listen on 80 and 443. alb.ingress.kubernetes.io/certificate-arn annotation must be set to allow listen for HTTPS traffic the ssl-redirect action must be be first rule(which will be evaluated first by ALB)","title":"Example Ingress Manifest"},{"location":"guide/tasks/ssl_redirect/#how-it-works","text":"By default, all rules specified in ingress spec will be applied to all listeners(one listener per port) on ALB. If there is an redirection rule, the ALB ingress controller will check it against every listener(port) to see whether it will introduce infinite redirection loop, and will ignore that rule for specific listener. So for our above example, the rule by ssl-redirect will only been applied to http(80) listener.","title":"How it works"},{"location":"guide/walkthrough/echoserver/","text":"walkthrough: echoserver \u00b6 In this walkthrough, you'll Create a cluster with EKS Deploy an alb-ingress-controller Create deployments and ingress resources in the cluster Use external-dns to create a DNS record This assumes you have a route53 hosted zone available. Otherwise you can skip this, but you'll only be able to address the service from the ALB's DNS. Create the EKS cluster \u00b6 Install eksctl : https://eksctl.io Create EKS cluster via eksctl eksctl create cluster 2018-08-14T11:19:09-07:00 [\u2139] setting availability zones to [us-west-2c us-west-2a us-west-2b] 2018-08-14T11:19:09-07:00 [\u2139] importing SSH public key \"/Users/kamador/.ssh/id_rsa.pub\" as \"eksctl-exciting-gopher-1534270749-b7:71:da:f6:f3:63:7a:ee:ad:7a:10:37:28:ff:44:d1\" 2018-08-14T11:19:10-07:00 [\u2139] creating EKS cluster \"exciting-gopher-1534270749\" in \"us-west-2\" region 2018-08-14T11:19:10-07:00 [\u2139] creating ServiceRole stack \"EKS-exciting-gopher-1534270749-ServiceRole\" 2018-08-14T11:19:10-07:00 [\u2139] creating VPC stack \"EKS-exciting-gopher-1534270749-VPC\" 2018-08-14T11:19:50-07:00 [\u2714] created ServiceRole stack \"EKS-exciting-gopher-1534270749-ServiceRole\" 2018-08-14T11:20:30-07:00 [\u2714] created VPC stack \"EKS-exciting-gopher-1534270749-VPC\" 2018-08-14T11:20:30-07:00 [\u2139] creating control plane \"exciting-gopher-1534270749\" 2018-08-14T11:31:52-07:00 [\u2714] created control plane \"exciting-gopher-1534270749\" 2018-08-14T11:31:52-07:00 [\u2139] creating DefaultNodeGroup stack \"EKS-exciting-gopher-1534270749-DefaultNodeGroup\" 2018-08-14T11:35:33-07:00 [\u2714] created DefaultNodeGroup stack \"EKS-exciting-gopher-1534270749-DefaultNodeGroup\" 2018-08-14T11:35:33-07:00 [\u2714] all EKS cluster \"exciting-gopher-1534270749\" resources has been created 2018-08-14T11:35:33-07:00 [\u2714] saved kubeconfig as \"/Users/kamador/.kube/config\" 2018-08-14T11:35:34-07:00 [\u2139] the cluster has 0 nodes 2018-08-14T11:35:34-07:00 [\u2139] waiting for at least 2 nodes to become ready 2018-08-14T11:36:05-07:00 [\u2139] the cluster has 2 nodes 2018-08-14T11:36:05-07:00 [\u2139] node \"ip-192-168-139-176.us-west-2.compute.internal\" is ready 2018-08-14T11:36:05-07:00 [\u2139] node \"ip-192-168-214-126.us-west-2.compute.internal\" is ready 2018-08-14T11:36:05-07:00 [\u2714] EKS cluster \"exciting-gopher-1534270749\" in \"us-west-2\" region is ready Deploy the ALB ingress controller \u00b6 Download the example alb-ingress-manifest locally. wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/alb-ingress-controller.yaml wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/rbac-role.yaml Edit the manifest and set the following parameters and environment variables. cluster-name : name of the cluster. AWS_ACCESS_KEY_ID : access key id that alb controller can use to communicate with AWS. This is only used for convenience of this example. It will keep the credentials in plain text within this manifest. It's recommended a project such as kube2iam is used to resolve access. You will need to uncomment this from the manifest . - name : AWS_ACCESS_KEY_ID value : KEYVALUE AWS_SECRET_ACCESS_KEY : secret access key that alb controller can use to communicate with AWS. This is only used for convenience of this example. It will keep the credentials in plain text within this manifest. It's recommended a project such as kube2iam is used to resolve access. You will need to uncomment this from the manifest . - name : AWS_SECRET_ACCESS_KEY value : SECRETVALUE Deploy the modified alb-ingress-controller. kubectl apply -f rbac-role.yaml kubectl apply -f alb-ingress-controller.yaml The manifest above will deploy the controller to the kube-system namespace. Verify the deployment was successful and the controller started. kubectl logs -n kube-system $( kubectl get po -n kube-system | egrep -o alb-ingress [ a-zA-Z0-9- ] + ) Should display output similar to the following. ------------------------------------------------------------------------------- AWS ALB Ingress controller Release: UNKNOWN Build: UNKNOWN Repository: UNKNOWN ------------------------------------------------------------------------------- I0725 11:22:06.464996 16433 main.go:159] Creating API client for http://localhost:8001 I0725 11:22:06.563336 16433 main.go:203] Running in Kubernetes cluster version v1.8+ (v1.8.9+coreos.1) - git (clean) commit cd373fe93e046b0a0bc7e4045af1bf4171cea395 - platform linux/amd64 I0725 11:22:06.566255 16433 alb.go:80] ALB resource names will be prefixed with 2f92da62 I0725 11:22:06.645910 16433 alb.go:163] Starting AWS ALB Ingress controller Deploy the echoserver resources \u00b6 Deploy all the echoserver resources (namespace, service, deployment) kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-namespace.yaml && \\ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-service.yaml && \\ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-deployment.yaml && \\ List all the resources to ensure they were created. kubectl get -n echoserver deploy,svc Should resolve similar to the following. NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE svc/echoserver 10.3.31.76 <nodes> 80:31027/TCP 4d NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deploy/echoserver 1 1 1 1 4d Deploy ingress for echoserver \u00b6 Download the echoserver ingress manifest locally. wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-ingress.yaml Configure the subnets, either by add annotation to the ingress or add tags to subnets. Tip If you'd like to use external dns, alter the host field to a domain that you own in Route 53. Assuming you managed example.com in Route 53. Edit the alb.ingress.kubernetes.io/subnets annotation to include at least two subnets. eksctl get cluster exciting-gopher-1534270749 NAME VERSION STATUS CREATED VPC SUBNETS SECURITYGROUPS exciting-gopher-1534270749 1.10 ACTIVE 2018-08-14T18:20:32Z vpc-0aa01b07b3c922c9c subnet-05e1c98ed0f5b109e,subnet-07f5bb81f661df61b,subnet-0a4e6232630820516 sg-05ceb5eee9fd7cac4 apiVersion : extensions/v1beta1 kind : Ingress metadata : name : echoserver namespace : echoserver annotations : alb.ingress.kubernetes.io/scheme : internet-facing alb.ingress.kubernetes.io/target-type : ip alb.ingress.kubernetes.io/subnets : subnet-05e1c98ed0f5b109e,subnet-07f5bb81f661df61b,subnet-0a4e6232630820516 alb.ingress.kubernetes.io/tags : Environment=dev,Team=test spec : rules : - host : echoserver.example.com http : paths : Adding tags to subnets for auto-discovery(instead of alb.ingress.kubernetes.io/subnets annotation) you must include the following tags on desired subnets. kubernetes.io/cluster/$CLUSTER_NAME where $CLUSTER_NAME is the same CLUSTER_NAME specified in the above step. kubernetes.io/role/internal-elb should be set to 1 or an empty tag value for internal load balancers. kubernetes.io/role/elb should be set to 1 or an empty tag value for internet-facing load balancers. An example of a subnet with the correct tags for the cluster joshcalico is as follows. Deploy the ingress resource for echoserver kubectl apply -f echoserver-ingress.yaml Verify the alb-ingress-controller creates the resources kubectl logs -n kube-system $( kubectl get po -n kube-system | egrep -o 'alb-ingress[a-zA-Z0-9-]+' ) | grep 'echoserver\\/echoserver' You should see similar to the following. echoserver/echoserver: Start ELBV2 (ALB) creation. echoserver/echoserver: Completed ELBV2 (ALB) creation. Name: joshcalico-echoserver-echo-2ad7 | ARN: arn:aws:elasticloadbalancing:us-east-2:432733164488:loadbalancer/app/joshcalico-echoserver-echo-2ad7/4579643c6f757be9 echoserver/echoserver: Start TargetGroup creation. echoserver/echoserver: Succeeded TargetGroup creation. ARN: arn:aws:elasticloadbalancing:us-east-2:432733164488:targetgroup/joshcalico-31027-HTTP-6657576/77ef58891a00263e | Name: joshcalico-31027-HTTP-6657576. echoserver/echoserver: Start Listener creation. echoserver/echoserver: Completed Listener creation. ARN: arn:aws:elasticloadbalancing:us-east-2:432733164488:listener/app/joshcalico-echoserver-echo-2ad7/4579643c6f757be9/2b2987fa3739c062 | Port: 80 | Proto: HTTP. echoserver/echoserver: Start Rule creation. echoserver/echoserver: Completed Rule creation. Rule Priority: \"1\" | Condition: [{ Field: \"host-header\", Values: [\"echoserver.joshrosso.com\"] },{ Field: \"path-pattern\", Values: [\"/\"] }] Check the events of the ingress to see what has occur. kubectl describe ing -n echoserver echoserver You should see similar to the following. Name: echoserver Namespace: echoserver Address: joshcalico-echoserver-echo-2ad7-1490890749.us-east-2.elb.amazonaws.com Default backend: default-http-backend:80 (10.2.1.28:8080) Rules: Host Path Backends ---- ---- -------- echoserver.joshrosso.com / echoserver:80 (<none>) Annotations: Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 3m 3m 1 ingress-controller Normal CREATE Ingress echoserver/echoserver 3m 32s 3 ingress-controller Normal UPDATE Ingress echoserver/echoserver The address seen above is the ALB's DNS record. This will be referenced via records created by external-dns. Setup external-DNS to manage DNS automatically \u00b6 Ensure your instance has the correct IAM permission required for external-dns. See https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/aws.md#iam-permissions. Download external-dns to manage Route 53. wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/external-dns.yaml Edit the --domain-filter flag to include your hosted zone(s) The following example is for a hosted zone test-dns.com args : - --source=service - --source=ingress - --domain-filter=test-dns.com # will make ExternalDNS see only the hosted zones matching provided domain, omit to process all available hosted zones - --provider=aws - --policy=upsert-only # would prevent ExternalDNS from deleting any records, omit to enable full synchronization Verify the DNS has propagated dig echoserver.josh-test-dns.com ;; QUESTION SECTION: ;echoserver.josh-test-dns.com. IN A ;; ANSWER SECTION: echoserver.josh-test-dns.com. 60 IN A 13.59.147.105 echoserver.josh-test-dns.com. 60 IN A 18.221.65.39 echoserver.josh-test-dns.com. 60 IN A 52.15.186.25 Once it has, you can make a call to echoserver and it should return a response payload. curl echoserver.josh-test-dns.com CLIENT VALUES: client_address=10.0.50.185 command=GET real path=/ query=nil request_version=1.1 request_uri=http://echoserver.josh-test-dns.com:8080/ SERVER VALUES: server_version=nginx: 1.10.0 - lua: 10001 HEADERS RECEIVED: accept=*/* host=echoserver.josh-test-dns.com user-agent=curl/7.54.0 x-amzn-trace-id=Root=1-59c08da5-113347df69640735312371bd x-forwarded-for=67.173.237.250 x-forwarded-port=80 x-forwarded-proto=http BODY: Kube2iam setup \u00b6 follow below steps If you want to use kube2iam to provide the AWS credentials configure the proper policy The policy to be used can be fetched from https://github.com/kubernetes-sigs/aws-alb-ingress-controller/blob/master/docs/examples/iam-policy.json configure the proper role and create the trust relationship You have to find which role is associated woth your K8S nodes. Once you found take note of the full arn: arn : aws : iam :: XXXXXXXXXXXX : role / k8scluster - node create the role, called k8s-alb-controller, attach the above policy and add a Trust Relationship like: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ec2.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" }, { \"Sid\": \"\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::XXXXXXXXXXXX:role/k8scluster-node\" }, \"Action\": \"sts:AssumeRole\" } ] } The new role will have the arn: arn : aws : iam ::: XXXXXXXXXXXX : role / k8s - alb - controller update the alb-ingress-controller.yaml Add the annotations in the template's metadata poin spec : replicas : 1 selector : matchLabels : app : alb-ingress-controller strategy : rollingUpdate : maxSurge : 1 maxUnavailable : 1 type : RollingUpdate template : metadata : annotations : iam.amazonaws.com/role : arn:aws:iam:::XXXXXXXXXXXX:role/k8s-alb-controller","title":"Echo server"},{"location":"guide/walkthrough/echoserver/#walkthrough-echoserver","text":"In this walkthrough, you'll Create a cluster with EKS Deploy an alb-ingress-controller Create deployments and ingress resources in the cluster Use external-dns to create a DNS record This assumes you have a route53 hosted zone available. Otherwise you can skip this, but you'll only be able to address the service from the ALB's DNS.","title":"walkthrough: echoserver"},{"location":"guide/walkthrough/echoserver/#create-the-eks-cluster","text":"Install eksctl : https://eksctl.io Create EKS cluster via eksctl eksctl create cluster 2018-08-14T11:19:09-07:00 [\u2139] setting availability zones to [us-west-2c us-west-2a us-west-2b] 2018-08-14T11:19:09-07:00 [\u2139] importing SSH public key \"/Users/kamador/.ssh/id_rsa.pub\" as \"eksctl-exciting-gopher-1534270749-b7:71:da:f6:f3:63:7a:ee:ad:7a:10:37:28:ff:44:d1\" 2018-08-14T11:19:10-07:00 [\u2139] creating EKS cluster \"exciting-gopher-1534270749\" in \"us-west-2\" region 2018-08-14T11:19:10-07:00 [\u2139] creating ServiceRole stack \"EKS-exciting-gopher-1534270749-ServiceRole\" 2018-08-14T11:19:10-07:00 [\u2139] creating VPC stack \"EKS-exciting-gopher-1534270749-VPC\" 2018-08-14T11:19:50-07:00 [\u2714] created ServiceRole stack \"EKS-exciting-gopher-1534270749-ServiceRole\" 2018-08-14T11:20:30-07:00 [\u2714] created VPC stack \"EKS-exciting-gopher-1534270749-VPC\" 2018-08-14T11:20:30-07:00 [\u2139] creating control plane \"exciting-gopher-1534270749\" 2018-08-14T11:31:52-07:00 [\u2714] created control plane \"exciting-gopher-1534270749\" 2018-08-14T11:31:52-07:00 [\u2139] creating DefaultNodeGroup stack \"EKS-exciting-gopher-1534270749-DefaultNodeGroup\" 2018-08-14T11:35:33-07:00 [\u2714] created DefaultNodeGroup stack \"EKS-exciting-gopher-1534270749-DefaultNodeGroup\" 2018-08-14T11:35:33-07:00 [\u2714] all EKS cluster \"exciting-gopher-1534270749\" resources has been created 2018-08-14T11:35:33-07:00 [\u2714] saved kubeconfig as \"/Users/kamador/.kube/config\" 2018-08-14T11:35:34-07:00 [\u2139] the cluster has 0 nodes 2018-08-14T11:35:34-07:00 [\u2139] waiting for at least 2 nodes to become ready 2018-08-14T11:36:05-07:00 [\u2139] the cluster has 2 nodes 2018-08-14T11:36:05-07:00 [\u2139] node \"ip-192-168-139-176.us-west-2.compute.internal\" is ready 2018-08-14T11:36:05-07:00 [\u2139] node \"ip-192-168-214-126.us-west-2.compute.internal\" is ready 2018-08-14T11:36:05-07:00 [\u2714] EKS cluster \"exciting-gopher-1534270749\" in \"us-west-2\" region is ready","title":"Create the EKS cluster"},{"location":"guide/walkthrough/echoserver/#deploy-the-alb-ingress-controller","text":"Download the example alb-ingress-manifest locally. wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/alb-ingress-controller.yaml wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/rbac-role.yaml Edit the manifest and set the following parameters and environment variables. cluster-name : name of the cluster. AWS_ACCESS_KEY_ID : access key id that alb controller can use to communicate with AWS. This is only used for convenience of this example. It will keep the credentials in plain text within this manifest. It's recommended a project such as kube2iam is used to resolve access. You will need to uncomment this from the manifest . - name : AWS_ACCESS_KEY_ID value : KEYVALUE AWS_SECRET_ACCESS_KEY : secret access key that alb controller can use to communicate with AWS. This is only used for convenience of this example. It will keep the credentials in plain text within this manifest. It's recommended a project such as kube2iam is used to resolve access. You will need to uncomment this from the manifest . - name : AWS_SECRET_ACCESS_KEY value : SECRETVALUE Deploy the modified alb-ingress-controller. kubectl apply -f rbac-role.yaml kubectl apply -f alb-ingress-controller.yaml The manifest above will deploy the controller to the kube-system namespace. Verify the deployment was successful and the controller started. kubectl logs -n kube-system $( kubectl get po -n kube-system | egrep -o alb-ingress [ a-zA-Z0-9- ] + ) Should display output similar to the following. ------------------------------------------------------------------------------- AWS ALB Ingress controller Release: UNKNOWN Build: UNKNOWN Repository: UNKNOWN ------------------------------------------------------------------------------- I0725 11:22:06.464996 16433 main.go:159] Creating API client for http://localhost:8001 I0725 11:22:06.563336 16433 main.go:203] Running in Kubernetes cluster version v1.8+ (v1.8.9+coreos.1) - git (clean) commit cd373fe93e046b0a0bc7e4045af1bf4171cea395 - platform linux/amd64 I0725 11:22:06.566255 16433 alb.go:80] ALB resource names will be prefixed with 2f92da62 I0725 11:22:06.645910 16433 alb.go:163] Starting AWS ALB Ingress controller","title":"Deploy the ALB ingress controller"},{"location":"guide/walkthrough/echoserver/#deploy-the-echoserver-resources","text":"Deploy all the echoserver resources (namespace, service, deployment) kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-namespace.yaml && \\ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-service.yaml && \\ kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-deployment.yaml && \\ List all the resources to ensure they were created. kubectl get -n echoserver deploy,svc Should resolve similar to the following. NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE svc/echoserver 10.3.31.76 <nodes> 80:31027/TCP 4d NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deploy/echoserver 1 1 1 1 4d","title":"Deploy the echoserver resources"},{"location":"guide/walkthrough/echoserver/#deploy-ingress-for-echoserver","text":"Download the echoserver ingress manifest locally. wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/echoservice/echoserver-ingress.yaml Configure the subnets, either by add annotation to the ingress or add tags to subnets. Tip If you'd like to use external dns, alter the host field to a domain that you own in Route 53. Assuming you managed example.com in Route 53. Edit the alb.ingress.kubernetes.io/subnets annotation to include at least two subnets. eksctl get cluster exciting-gopher-1534270749 NAME VERSION STATUS CREATED VPC SUBNETS SECURITYGROUPS exciting-gopher-1534270749 1.10 ACTIVE 2018-08-14T18:20:32Z vpc-0aa01b07b3c922c9c subnet-05e1c98ed0f5b109e,subnet-07f5bb81f661df61b,subnet-0a4e6232630820516 sg-05ceb5eee9fd7cac4 apiVersion : extensions/v1beta1 kind : Ingress metadata : name : echoserver namespace : echoserver annotations : alb.ingress.kubernetes.io/scheme : internet-facing alb.ingress.kubernetes.io/target-type : ip alb.ingress.kubernetes.io/subnets : subnet-05e1c98ed0f5b109e,subnet-07f5bb81f661df61b,subnet-0a4e6232630820516 alb.ingress.kubernetes.io/tags : Environment=dev,Team=test spec : rules : - host : echoserver.example.com http : paths : Adding tags to subnets for auto-discovery(instead of alb.ingress.kubernetes.io/subnets annotation) you must include the following tags on desired subnets. kubernetes.io/cluster/$CLUSTER_NAME where $CLUSTER_NAME is the same CLUSTER_NAME specified in the above step. kubernetes.io/role/internal-elb should be set to 1 or an empty tag value for internal load balancers. kubernetes.io/role/elb should be set to 1 or an empty tag value for internet-facing load balancers. An example of a subnet with the correct tags for the cluster joshcalico is as follows. Deploy the ingress resource for echoserver kubectl apply -f echoserver-ingress.yaml Verify the alb-ingress-controller creates the resources kubectl logs -n kube-system $( kubectl get po -n kube-system | egrep -o 'alb-ingress[a-zA-Z0-9-]+' ) | grep 'echoserver\\/echoserver' You should see similar to the following. echoserver/echoserver: Start ELBV2 (ALB) creation. echoserver/echoserver: Completed ELBV2 (ALB) creation. Name: joshcalico-echoserver-echo-2ad7 | ARN: arn:aws:elasticloadbalancing:us-east-2:432733164488:loadbalancer/app/joshcalico-echoserver-echo-2ad7/4579643c6f757be9 echoserver/echoserver: Start TargetGroup creation. echoserver/echoserver: Succeeded TargetGroup creation. ARN: arn:aws:elasticloadbalancing:us-east-2:432733164488:targetgroup/joshcalico-31027-HTTP-6657576/77ef58891a00263e | Name: joshcalico-31027-HTTP-6657576. echoserver/echoserver: Start Listener creation. echoserver/echoserver: Completed Listener creation. ARN: arn:aws:elasticloadbalancing:us-east-2:432733164488:listener/app/joshcalico-echoserver-echo-2ad7/4579643c6f757be9/2b2987fa3739c062 | Port: 80 | Proto: HTTP. echoserver/echoserver: Start Rule creation. echoserver/echoserver: Completed Rule creation. Rule Priority: \"1\" | Condition: [{ Field: \"host-header\", Values: [\"echoserver.joshrosso.com\"] },{ Field: \"path-pattern\", Values: [\"/\"] }] Check the events of the ingress to see what has occur. kubectl describe ing -n echoserver echoserver You should see similar to the following. Name: echoserver Namespace: echoserver Address: joshcalico-echoserver-echo-2ad7-1490890749.us-east-2.elb.amazonaws.com Default backend: default-http-backend:80 (10.2.1.28:8080) Rules: Host Path Backends ---- ---- -------- echoserver.joshrosso.com / echoserver:80 (<none>) Annotations: Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 3m 3m 1 ingress-controller Normal CREATE Ingress echoserver/echoserver 3m 32s 3 ingress-controller Normal UPDATE Ingress echoserver/echoserver The address seen above is the ALB's DNS record. This will be referenced via records created by external-dns.","title":"Deploy ingress for echoserver"},{"location":"guide/walkthrough/echoserver/#setup-external-dns-to-manage-dns-automatically","text":"Ensure your instance has the correct IAM permission required for external-dns. See https://github.com/kubernetes-incubator/external-dns/blob/master/docs/tutorials/aws.md#iam-permissions. Download external-dns to manage Route 53. wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/master/docs/examples/external-dns.yaml Edit the --domain-filter flag to include your hosted zone(s) The following example is for a hosted zone test-dns.com args : - --source=service - --source=ingress - --domain-filter=test-dns.com # will make ExternalDNS see only the hosted zones matching provided domain, omit to process all available hosted zones - --provider=aws - --policy=upsert-only # would prevent ExternalDNS from deleting any records, omit to enable full synchronization Verify the DNS has propagated dig echoserver.josh-test-dns.com ;; QUESTION SECTION: ;echoserver.josh-test-dns.com. IN A ;; ANSWER SECTION: echoserver.josh-test-dns.com. 60 IN A 13.59.147.105 echoserver.josh-test-dns.com. 60 IN A 18.221.65.39 echoserver.josh-test-dns.com. 60 IN A 52.15.186.25 Once it has, you can make a call to echoserver and it should return a response payload. curl echoserver.josh-test-dns.com CLIENT VALUES: client_address=10.0.50.185 command=GET real path=/ query=nil request_version=1.1 request_uri=http://echoserver.josh-test-dns.com:8080/ SERVER VALUES: server_version=nginx: 1.10.0 - lua: 10001 HEADERS RECEIVED: accept=*/* host=echoserver.josh-test-dns.com user-agent=curl/7.54.0 x-amzn-trace-id=Root=1-59c08da5-113347df69640735312371bd x-forwarded-for=67.173.237.250 x-forwarded-port=80 x-forwarded-proto=http BODY:","title":"Setup external-DNS to manage DNS automatically"},{"location":"guide/walkthrough/echoserver/#kube2iam-setup","text":"follow below steps If you want to use kube2iam to provide the AWS credentials configure the proper policy The policy to be used can be fetched from https://github.com/kubernetes-sigs/aws-alb-ingress-controller/blob/master/docs/examples/iam-policy.json configure the proper role and create the trust relationship You have to find which role is associated woth your K8S nodes. Once you found take note of the full arn: arn : aws : iam :: XXXXXXXXXXXX : role / k8scluster - node create the role, called k8s-alb-controller, attach the above policy and add a Trust Relationship like: { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"\", \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"ec2.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" }, { \"Sid\": \"\", \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::XXXXXXXXXXXX:role/k8scluster-node\" }, \"Action\": \"sts:AssumeRole\" } ] } The new role will have the arn: arn : aws : iam ::: XXXXXXXXXXXX : role / k8s - alb - controller update the alb-ingress-controller.yaml Add the annotations in the template's metadata poin spec : replicas : 1 selector : matchLabels : app : alb-ingress-controller strategy : rollingUpdate : maxSurge : 1 maxUnavailable : 1 type : RollingUpdate template : metadata : annotations : iam.amazonaws.com/role : arn:aws:iam:::XXXXXXXXXXXX:role/k8s-alb-controller","title":"Kube2iam setup"}]}